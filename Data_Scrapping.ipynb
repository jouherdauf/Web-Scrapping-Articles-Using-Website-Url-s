{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jouherdauf/Web-Scrapping-Articles-Using-Website-Url-s/blob/main/Data_Scrapping.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af3902d5",
      "metadata": {
        "id": "af3902d5"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import urllib.parse\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from google.colab import files\n",
        "data = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "450876bb",
      "metadata": {
        "id": "450876bb"
      },
      "outputs": [],
      "source": [
        "#importing the input file\n",
        "df = pd.read_csv('Input.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb07ed3c",
      "metadata": {
        "id": "bb07ed3c"
      },
      "outputs": [],
      "source": [
        "#dropping the row where URL iss null\n",
        "df.dropna(subset=['URL'],inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "95f0cd44",
      "metadata": {
        "id": "95f0cd44"
      },
      "outputs": [],
      "source": [
        "# creating column where we upadate URL content in string format\n",
        "df['response'] = np.nan"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce56a5bb",
      "metadata": {
        "id": "ce56a5bb"
      },
      "outputs": [],
      "source": [
        "#saving text file of URL content & updating response column\n",
        "for i  in df.index:\n",
        "  try:\n",
        "    url = df.loc[i,\"URL\"]\n",
        "    string = requests.get(url)\n",
        "    html_content = string.content\n",
        "# Parse the HTML using Beautiful Soup\n",
        "    soup = BeautifulSoup(html_content, \"html.parser\")\n",
        "    paragraphs = soup.find_all(\"h1\")\n",
        "    division = soup.find_all(\"div\", {\"class\": \"tagdiv-type\"})\n",
        "    paragraphs.extend(division)\n",
        "    texts = [paragraph.get_text() for paragraph in paragraphs]\n",
        "    abc = ''\n",
        "    for paragrap in texts:\n",
        "        abc += f'''{paragrap}'''\n",
        "    df.at[i,'response'] = abc\n",
        "    with open(f'{df.loc[i,\"URL_ID\"]}.txt', 'w',encoding=\"utf-8\") as file:\n",
        "        file.write(abc)\n",
        "  except:\n",
        "    df.at[i,'response'] = np.nan"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ded00eaf",
      "metadata": {
        "id": "ded00eaf"
      },
      "outputs": [],
      "source": [
        "#copying the dataframe\n",
        "df1 = df.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "937498f5",
      "metadata": {
        "id": "937498f5"
      },
      "outputs": [],
      "source": [
        "#dropping the \\n from the string\n",
        "for i in df.index:\n",
        "    df1.loc[i,'response'] = df1.loc[i,'response'].replace('\\n',' ')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "89d6a9bf",
      "metadata": {
        "id": "89d6a9bf"
      },
      "source": [
        "#### Creating List of all stopwords and merging it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5cfd3b6f",
      "metadata": {
        "id": "5cfd3b6f"
      },
      "outputs": [],
      "source": [
        "StopWordsNames = []\n",
        "file = open(\"StopWords_Names.txt\", \"r\")\n",
        "for line in file:\n",
        "  stripped_line = line.strip()\n",
        "  StopWordsNames.append(stripped_line)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "95d1d9b8",
      "metadata": {
        "id": "95d1d9b8"
      },
      "outputs": [],
      "source": [
        "StopWordsGeographic = []\n",
        "file = open(\"StopWords_Geographic.txt\", \"r\")\n",
        "for line in file:\n",
        "  stripped_line = line.strip()\n",
        "  StopWordsGeographic.append(stripped_line)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f7d05cfe",
      "metadata": {
        "id": "f7d05cfe"
      },
      "outputs": [],
      "source": [
        "StopWordsGenericLong = []\n",
        "file = open(\"StopWords_GenericLong.txt\", \"r\")\n",
        "for line in file:\n",
        "  stripped_line = line.strip()\n",
        "  StopWordsGenericLong.append(stripped_line)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a4da92b7",
      "metadata": {
        "id": "a4da92b7"
      },
      "outputs": [],
      "source": [
        "StopWordsGeneric = []\n",
        "file = open(\"StopWords_Generic.txt\", \"r\")\n",
        "for line in file:\n",
        "  stripped_line = line.strip()\n",
        "  StopWordsGeneric.append(stripped_line)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7140a26c",
      "metadata": {
        "id": "7140a26c"
      },
      "outputs": [],
      "source": [
        "StopWordsAuditor = []\n",
        "file = open(\"StopWords_Auditor.txt\", \"r\")\n",
        "for line in file:\n",
        "  stripped_line = line.strip()\n",
        "  StopWordsAuditor.append(stripped_line)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f129f8cc",
      "metadata": {
        "id": "f129f8cc"
      },
      "outputs": [],
      "source": [
        "StopWordsDatesandNumbers = []\n",
        "file = open(\"StopWords_DatesandNumbers.txt\", \"r\")\n",
        "for line in file:\n",
        "  stripped_line = line.strip()\n",
        "  StopWordsDatesandNumbers.append(stripped_line)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b61ba3bb",
      "metadata": {
        "id": "b61ba3bb"
      },
      "outputs": [],
      "source": [
        "StopWordsCurrencies = []\n",
        "file = open(\"StopWords_Currencies.txt\", \"r\")\n",
        "for line in file:\n",
        "  stripped_line = line.strip()\n",
        "  StopWordsCurrencies.append(stripped_line)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "024fb4e9",
      "metadata": {
        "id": "024fb4e9"
      },
      "outputs": [],
      "source": [
        "#merging all the stopwords\n",
        "stopwordslists = [StopWordsCurrencies,StopWordsDatesandNumbers,StopWordsAuditor,StopWordsGeneric,StopWordsGenericLong,StopWordsGeographic,StopWordsNames]\n",
        "stopwords = []\n",
        "for i in stopwordslists:\n",
        "    for j in i:\n",
        "        stopwords.append(j)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "06c8b54f",
      "metadata": {
        "id": "06c8b54f"
      },
      "outputs": [],
      "source": [
        "#removing stop word from the string\n",
        "for i in df.index:\n",
        "    for j in stopwords:\n",
        "        df1.loc[i,'response'] = df1.loc[i,'response'].replace(' '+j+' ',' ')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4bfb73bd",
      "metadata": {
        "id": "4bfb73bd"
      },
      "outputs": [],
      "source": [
        "# removing pre tag from the string\n",
        "words =''\n",
        "for i in df1.index:\n",
        "    x = 0\n",
        "    for j in df1.loc[i,'response']:\n",
        "        words += j\n",
        "        x += 1\n",
        "        if words[-11:] == 'Blackcoffer':\n",
        "            df1.loc[i,'response'] = df1.loc[i,'response'][0:x-11]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81ed911a",
      "metadata": {
        "id": "81ed911a"
      },
      "outputs": [],
      "source": [
        "#Creating list of all words\n",
        "df1['words'] = ''\n",
        "import re\n",
        "def split_sentence(sentence):\n",
        "    return re.findall(r'\\b\\w+\\b', sentence)\n",
        "#Driver code\n",
        "for i in df1.index:\n",
        "    sentence = df1.loc[i,'response'][:]\n",
        "    df1.at[i,'words'] = split_sentence(sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1a5c5ca",
      "metadata": {
        "id": "a1a5c5ca"
      },
      "outputs": [],
      "source": [
        "# counting number of words\n",
        "df1['WORD COUNT'] = np.nan\n",
        "\n",
        "for i in df1.index:\n",
        "    count = 0\n",
        "    for j in df1.loc[i,'words']:\n",
        "        if  j[0] not in  ['0','1','2','3','4','5','6','7','8','9']:\n",
        "            count += 1\n",
        "            df1.loc[i,'WORD COUNT'] = count\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d54dab3",
      "metadata": {
        "id": "7d54dab3"
      },
      "outputs": [],
      "source": [
        "# average word length\n",
        "df1['AVG WORD LENGTH'] = np.nan\n",
        "for i in df1.index:\n",
        "    count = 0\n",
        "    for j in df1.loc[i,'words']:\n",
        "        if  j[0] not in  ['0','1','2','3','4','5','6','7','8','9']:\n",
        "            count += len(j)\n",
        "            df1.loc[i,'AVG WORD LENGTH'] = count/df1.loc[i,'WORD COUNT']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f204932e",
      "metadata": {
        "id": "f204932e"
      },
      "outputs": [],
      "source": [
        "#function to count number of syllable\n",
        "def syllable_count(word):\n",
        "    word = word.lower()\n",
        "    count = 0\n",
        "    vowels = \"aeiou\"\n",
        "    if word[0] in vowels:\n",
        "        count += 1\n",
        "    for index in range(1, len(word)):\n",
        "        if word[index] in vowels and word[index - 1] not in vowels:\n",
        "            count += 1\n",
        "    if word.endswith(\"e\"):\n",
        "        count -= 1\n",
        "    if count == 0:\n",
        "        count += 1\n",
        "    return count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e2ac662",
      "metadata": {
        "id": "7e2ac662"
      },
      "outputs": [],
      "source": [
        "#checking the number of complex words\n",
        "words =''\n",
        "alphabets = ['a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x','y','z','A','B','C','D','E','F','G','H','I','J','K','L','M','N','O','P','Q','R','S','T','U','V','W','X','Y','Z']\n",
        "df1['Complex_words'] = np.nan\n",
        "for i in df1.index:\n",
        "    x = 0\n",
        "    for j in df1.loc[i,'response']:\n",
        "        if j in alphabets:\n",
        "            words += j\n",
        "        elif words == '':\n",
        "            words = ''\n",
        "        else:\n",
        "            if words[-2:] not in ['es','ed']:\n",
        "                syllable = syllable_count(words)\n",
        "                words = ''\n",
        "                if syllable > 2:\n",
        "                    x += 1\n",
        "                    df1.at[i,'Complex_words'] = x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d8f9dbef",
      "metadata": {
        "id": "d8f9dbef"
      },
      "outputs": [],
      "source": [
        "#checking the number of average number of syllable per word\n",
        "words =''\n",
        "alphabets = ['a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x','y','z','A','B','C','D','E','F','G','H','I','J','K','L','M','N','O','P','Q','R','S','T','U','V','W','X','Y','Z']\n",
        "df1['SYLLABLE PER WORD'] = np.nan\n",
        "for i in df1.index:\n",
        "    x = 0\n",
        "    for j in df1.loc[i,'response']:\n",
        "        if j in alphabets:\n",
        "            words += j\n",
        "        elif words == '':\n",
        "            words = ''\n",
        "        else:\n",
        "            if words[-2:] not in ['es','ed']:\n",
        "                syllable = syllable_count(words)\n",
        "                x += syllable\n",
        "                df1.at[i,'SYLLABLE PER WORD'] =  x/(df1.loc[i,'WORD COUNT'])\n",
        "                words = ''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ffba0568",
      "metadata": {
        "id": "ffba0568"
      },
      "outputs": [],
      "source": [
        "# NUmber of complex words\n",
        "df1['Complex_words'] = np.nan\n",
        "for i in df1.index:\n",
        "    x = 0\n",
        "    for j in df1.loc[i,'response']:\n",
        "        if j in alphabets:\n",
        "            words += j\n",
        "        elif words == '':\n",
        "            words = ''\n",
        "        else:\n",
        "            if words[-2:] not in ['es','ed']:\n",
        "                syllable = syllable_count(words)\n",
        "                words = ''\n",
        "                if syllable > 2:\n",
        "                    x += 1\n",
        "                    df1.at[i,'Complex_words'] = x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c485c0a5",
      "metadata": {
        "id": "c485c0a5"
      },
      "outputs": [],
      "source": [
        "#Checking percentage of complex words\n",
        "df1['Percentage OF COMPLEX WORDS'] = (df1['Complex_words']/df1['WORD COUNT'])*100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "16360cc8",
      "metadata": {
        "id": "16360cc8"
      },
      "outputs": [],
      "source": [
        "# creating list of positive words\n",
        "positivewords = []\n",
        "file = open(\"positive-words.txt\", \"r\")\n",
        "for line in file:\n",
        "  stripped_line = line.strip()\n",
        "  positivewords.append(stripped_line)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a454d88",
      "metadata": {
        "id": "7a454d88"
      },
      "outputs": [],
      "source": [
        "# creating list of negative words\n",
        "negativewords = []\n",
        "file = open(\"negative-words.txt\", \"r\")\n",
        "for line in file:\n",
        "  stripped_line = line.strip()\n",
        "  negativewords.append(stripped_line)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "25c53dab",
      "metadata": {
        "id": "25c53dab"
      },
      "outputs": [],
      "source": [
        "# creating  a column of negative words\n",
        "for i in df1.index:\n",
        "    x =0\n",
        "    for j in df1.loc[i,'words']:\n",
        "        if j in positivewords:\n",
        "            x += 1\n",
        "            df1.loc[i,'POSITIVE WORDS'] = x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c20f6c16",
      "metadata": {
        "id": "c20f6c16"
      },
      "outputs": [],
      "source": [
        "#creating a column of positive words\n",
        "for i in df1.index:\n",
        "    x =0\n",
        "    for j in df1.loc[i,'words']:\n",
        "        if j in negativewords:\n",
        "            x += 1\n",
        "            df1.loc[i,'NEGATIVE WORDS'] = x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c278af25",
      "metadata": {
        "id": "c278af25"
      },
      "outputs": [],
      "source": [
        "#Calculating Polarity Score\n",
        "df1['POLARITY SCORE'] = (df1['POSITIVE WORDS'] - df1['NEGATIVE WORDS'])/ ((df1['POSITIVE WORDS'] + df1['NEGATIVE WORDS']) + 0.000001)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "40f42013",
      "metadata": {
        "id": "40f42013"
      },
      "outputs": [],
      "source": [
        "df1['SUBJECTIVITY SCORE'] = (df1['POSITIVE WORDS'] - df1['NEGATIVE WORDS'])/ (df1['WORD COUNT'] + 0.000001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "587ebcc4",
      "metadata": {
        "id": "587ebcc4"
      },
      "outputs": [],
      "source": [
        "# calculate number of sentences in the article\n",
        "df1['Number of Sentences'] = np.nan\n",
        "for i in df1.index:\n",
        "    x =0\n",
        "    words = ''\n",
        "    for j in df1.loc[i,'response']:\n",
        "        words += j\n",
        "        if words[-2:] == '. ':\n",
        "            x += 1\n",
        "            df1.at[i,'Number of Sentences'] = x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dbf650fa",
      "metadata": {
        "id": "dbf650fa"
      },
      "outputs": [],
      "source": [
        "#Average  Number of words in each sentence\n",
        "df1['Average Number of Words Per Sentence'] = df1['WORD COUNT']/df1['Number of Sentences']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82d1bf98",
      "metadata": {
        "id": "82d1bf98"
      },
      "outputs": [],
      "source": [
        "df1['AVG SENTENCE LENGTH'] = df1['WORD COUNT']/df1['Number of Sentences']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aea1efb3",
      "metadata": {
        "id": "aea1efb3"
      },
      "outputs": [],
      "source": [
        "#Checking fog index\n",
        "df1['FOG INDEX'] = 0.4*(df1['Average Number of Words Per Sentence'] + df1['Percentage OF COMPLEX WORDS'] )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "20d56739",
      "metadata": {
        "id": "20d56739"
      },
      "outputs": [],
      "source": [
        "#Checking number of pronouns\n",
        "df1['PERSONAL PRONOUNS'] = np.nan\n",
        "for i in df1.index:\n",
        "    x= 0\n",
        "    for j in df1.loc[i,'words']:\n",
        "        if j == 'US':\n",
        "            x = x\n",
        "        elif j.lower() in [\"i\", \"you\", \"he\", \"she\", \"it\", \"we\", \"they\", \"them\", \"us\", \"him\", \"her\", \"his\", \"hers\", \"its\", \"theirs\", \"our\", \"your\"]:\n",
        "            x += 1\n",
        "            df1.at[i,'PERSONAL PRONOUNS'] = x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d8320b9f",
      "metadata": {
        "id": "d8320b9f"
      },
      "outputs": [],
      "source": [
        "df1.to_csv('Output.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bebfcdee",
      "metadata": {
        "id": "bebfcdee"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e6d206f8",
      "metadata": {
        "id": "e6d206f8"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}